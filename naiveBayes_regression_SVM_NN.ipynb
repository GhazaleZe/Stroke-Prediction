{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "technological-color",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import statsmodels.tools.tools as stattools\n",
    "import jenkspy\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sixth-lloyd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('E:\\\\term8\\\\datamining\\\\HW\\\\project\\\\prepared_data.csv')\n",
    "breaks = jenkspy.jenks_breaks(df['age'],nb_class = 5)\n",
    "df['agebin'] = pd.cut(x = df['age'], bins = breaks, right = False, labels = [1,2,3,4,5])\n",
    "\n",
    "breaks = jenkspy.jenks_breaks(df['bmi'],nb_class = 5)\n",
    "df['bmibin'] = pd.cut(x = df['bmi'], bins = breaks, right = False, labels = [1,2,3,4,5])\n",
    "\n",
    "breaks = jenkspy.jenks_breaks(df['avg_glucose_level'],nb_class = 5)\n",
    "df['glubin'] = pd.cut(x = df['avg_glucose_level'], bins = breaks, right = False, labels = [1,2,3,4,5])\n",
    "df = df.drop(columns = ['age', 'bmi', 'avg_glucose_level'])\n",
    "df = pd.get_dummies(df, columns = ['agebin', 'bmibin', 'glubin'])\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size = 0.2, random_state = 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "decent-amateur",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.03 ms\n",
      "Wall time: 14.8 ms\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.70      0.81       782\n",
      "           1       0.16      0.77      0.26        57\n",
      "\n",
      "    accuracy                           0.70       839\n",
      "   macro avg       0.57      0.74      0.54       839\n",
      "weighted avg       0.92      0.70      0.78       839\n",
      "\n",
      "[[546 236]\n",
      " [ 13  44]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\term6\\Anaconda\\setUp\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "temp = df_train[df['stroke'] == 1]\n",
    "temp = temp.sample(n = len(df_train[df_train['stroke'] == 0]) - len(df_train[df_train['stroke'] == 1]),\n",
    "                   replace = True)#20% of data: 800\n",
    "df_train = pd.concat([df_train, temp])\n",
    "y = df_train['stroke'].values\n",
    "df_train = df_train.drop(columns = ['stroke'])\n",
    "X = df_train.values\n",
    "y_test = df_test['stroke'].values\n",
    "df_test = df_test.drop(columns = ['stroke'])\n",
    "X_test = df_test.values\n",
    "%time nb_01 = MultinomialNB().fit(X, y)\n",
    "%time Y_pred = nb_01.predict(X_test)\n",
    "print(classification_report(y_test, Y_pred))\n",
    "print(confusion_matrix(y_test, Y_pred, labels = [0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "basic-identifier",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\term6\\Anaconda\\setUp\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 30.2 ms\n",
      "Wall time: 12.1 ms\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.73      0.83       782\n",
      "         1.0       0.16      0.74      0.27        57\n",
      "\n",
      "    accuracy                           0.73       839\n",
      "   macro avg       0.57      0.73      0.55       839\n",
      "weighted avg       0.92      0.73      0.79       839\n",
      "\n",
      "[[567 215]\n",
      " [ 15  42]]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('E:\\\\term8\\\\datamining\\\\HW\\\\project\\\\prepared_data.csv')\n",
    "df_train, df_test = train_test_split(df, test_size = 0.2, random_state = 45) \n",
    "temp = df_train[df['stroke'] == 1]\n",
    "temp = temp.sample(n = len(df_train[df_train['stroke'] == 0]) - len(df_train[df_train['stroke'] == 1]),\n",
    "                   replace = True)#20% of data: 800\n",
    "df_train = pd.concat([df_train, temp])\n",
    "X = df_train.values[:, 0:20]\n",
    "y = df_train.values[:, 20]\n",
    "X_test = df_test.values[:, 0:20]\n",
    "y_test = df_test.values[:, 20]\n",
    "%time clf = LogisticRegression(random_state=0).fit(X, y)\n",
    "%time Y_pred = (clf.predict_proba(X_test)[:,1]>0.5)*1\n",
    "print(classification_report(y_test, Y_pred))\n",
    "print(confusion_matrix(y_test, Y_pred, labels = [0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "applied-hebrew",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.59 s\n",
      "Wall time: 404 ms\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.70      0.82       782\n",
      "         1.0       0.15      0.72      0.25        57\n",
      "\n",
      "    accuracy                           0.70       839\n",
      "   macro avg       0.56      0.71      0.53       839\n",
      "weighted avg       0.92      0.70      0.78       839\n",
      "\n",
      "[[550 232]\n",
      " [ 16  41]]\n"
     ]
    }
   ],
   "source": [
    "%time clf = SVC(gamma='auto').fit(X, y)\n",
    "%time Y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, Y_pred))\n",
    "print(confusion_matrix(y_test, Y_pred, labels = [0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "automotive-porter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.27334099 0.44813564 0.56111464 0.64584444 0.72907815 0.78338199\n",
      " 0.83310977 0.87021602 0.90519734 0.93691883 0.96449501 0.98525364\n",
      " 0.99989069 0.9999606  1.         1.         1.         1.\n",
      " 1.         1.        ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca_m = PCA(n_components=20).fit(X)\n",
    "print(np.cumsum(pca_m.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "known-patio",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.95 s\n",
      "Wall time: 829 ms\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.71      0.82       782\n",
      "         1.0       0.15      0.70      0.25        57\n",
      "\n",
      "    accuracy                           0.71       839\n",
      "   macro avg       0.56      0.71      0.54       839\n",
      "weighted avg       0.91      0.71      0.78       839\n",
      "\n",
      "[[558 224]\n",
      " [ 17  40]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "X = df_train.values[:, 0:20]\n",
    "y = df_train.values[:, 20]\n",
    "X_test = df_test.values[:, 0:20]\n",
    "y_test = df_test.values[:, 20]\n",
    "pca_m = PCA(n_components=14).fit(X)\n",
    "X = pca_m.transform(X)\n",
    "X_test = pca_m.transform(X_test)\n",
    "clf = SVC(gamma='auto')\n",
    "%time clf.fit(X, y)\n",
    "%time Y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, Y_pred))\n",
    "print(confusion_matrix(y_test, Y_pred, labels = [0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "italian-genesis",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\term6\\Anaconda\\setUp\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.3 s\n",
      "Wall time: 7.56 ms\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.73      0.84       782\n",
      "         1.0       0.16      0.72      0.27        57\n",
      "\n",
      "    accuracy                           0.73       839\n",
      "   macro avg       0.57      0.73      0.55       839\n",
      "weighted avg       0.92      0.73      0.80       839\n",
      "\n",
      "[[572 210]\n",
      " [ 16  41]]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('E:\\\\term8\\\\datamining\\\\HW\\\\project\\\\prepared_data.csv')\n",
    "df_train, df_test = train_test_split(df, test_size = 0.2, random_state = 45) \n",
    "temp = df_train[df['stroke'] == 1]\n",
    "temp = temp.sample(n = len(df_train[df_train['stroke'] == 0]) - len(df_train[df_train['stroke'] == 1]),\n",
    "                   replace = True)#20% of data: 800\n",
    "df_train = pd.concat([df_train, temp])\n",
    "X = df_train.values[:, 0:20]\n",
    "y = df_train.values[:, 20]\n",
    "X_test = df_test.values[:, 0:20]\n",
    "y_test = df_test.values[:, 20]\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100), max_iter=300,activation = 'relu', solver = 'adam', alpha=1)\n",
    "%time mlp.fit(X, y)\n",
    "%time Y_pred = mlp.predict(X_test)\n",
    "print(classification_report(y_test, Y_pred))\n",
    "print(confusion_matrix(y_test, Y_pred, labels = [0, 1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow] *",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
